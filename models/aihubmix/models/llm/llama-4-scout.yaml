model: llama-4-scout
label:
  en_US: Llama 4 Scout
model_type: llm
features:
  - agent-thought
  - tool-call
  - stream-tool-call
  - multi-tool-call
  - vision
model_properties:
  mode: chat
  context_size: 131000
parameter_rules:
  - name: temperature
    use_template: temperature
  - name: top_p
    use_template: top_p
  - name: max_tokens
    use_template: max_tokens
    default: 8192
    min: 1
    max: 131000
  - name: response_format
    label:
      zh_Hans: 回复格式
      en_US: Response Format
    type: string
    required: false
    options:
      - text
      - json_object
      - json_schema
  - name: json_schema
    use_template: json_schema
pricing:
  input: '0.2'
  output: '0.2'
  unit: '0.000001'
  currency: USD
